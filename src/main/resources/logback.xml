<!-- Logback configuration. See http://logback.qos.ch/manual/index.html -->
<configuration scan="true" scanPeriod="10 seconds">
    <!--<property name="logDir" value="E:/testlog" />-->
    <!-- Simple file output -->
  <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <!--<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">-->
    <!-- encoder defaults to ch.qos.logback.classic.encoder.PatternLayoutEncoder -->
    <encoder>
        <pattern>
            [%-5level] [%date{yyyy-MM-dd HH:mm:ss}] %logger{96}:%line - %msg%n
        </pattern>
        <charset>UTF-8</charset>
    </encoder>

    <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">

      <fileNamePattern>logs/kp_diag_streaming-%d{yyyy-MM-dd}.%i.log</fileNamePattern>
      <timeBasedFileNamingAndTriggeringPolicy
          class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
        <!-- or whenever the file size reaches 64 MB -->
        <maxFileSize>64 MB</maxFileSize>
      </timeBasedFileNamingAndTriggeringPolicy>
    </rollingPolicy>


    <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
      <level>DEBUG</level>
    </filter>
    <!-- Safely log to the same file from multiple JVMs. Degrades performance! -->
    <prudent>true</prudent>
  </appender>


  <!-- Console output -->
  <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
    <!-- encoder defaults to ch.qos.logback.classic.encoder.PatternLayoutEncoder -->
      <encoder>
          <pattern>
              [ %-5level] [%date{yyyy-MM-dd HH:mm:ss}] %logger{96} [%line] - %msg%n
          </pattern>
          <charset>UTF-8</charset>
      </encoder>
    <!-- Only log level WARN and above -->
    <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
      <level>INFO</level>
    </filter>
  </appender>



    <appender name="KAFKA"
              class="com.xuele.log.send.kafka.KafkaAppender">
        <topic>${kafka.log.topic}</topic>
        <brokers>${kafka.brokers}</brokers>
        <timeout>${kafka.log.write.timeout}</timeout>
        <syncSend>${kafka.syncSend}</syncSend>
        <!--<zkHost>192.168.201.6:2181</zkHost>-->
        <!--<kafkaProducerProperties>-->
            <!--bootstrap.servers=192.168.201.6:9092,192.168.201.7:9092,192.168.201.8:9092-->
            <!--value.serializer=org.apache.kafka.common.serialization.StringSerializer-->
            <!--key.serializer=org.apache.kafka.common.serialization.StringSerializer-->
        <!--</kafkaProducerProperties>-->
        <logToSystemOut>true</logToSystemOut>
        <!-- specify a custom formatter -->
        <formatter class="com.xuele.log.send.kafka.formatter.JsonFormatter">
        <!--<formatter class="com.xuele.log.send.kafka.formatter.MessageFormatter">-->
            <!--
            Whether we expect the log message to be JSON encoded or not.
            If set to "false", the log message will be treated as a string,
            and wrapped in quotes. Otherwise it will be treated as a parseable
            JSON object.
            -->
            <expectJsonMessage>true</expectJsonMessage>
            <!-- Optional -->
            <includeMethodAndLineNumber>true</includeMethodAndLineNumber>
            <!-- Mark every message with these additional properties.-->
            <extraProperties>
            </extraProperties>
        </formatter>
    </appender>


    <root level="debug">
        <appender-ref ref="KAFKA" />
    </root>

  <!-- Enable FILE and STDOUT appenders for all log messages.
       By default, only log at level INFO and above. -->
  <root level="INFO">
      <appender-ref ref="STDOUT" />
      <appender-ref ref="FILE" />
      <appender-ref ref="KAFKA" />
  </root>

  <!-- For loggers in the these namespaces, log at all levels. -->
  <logger name="pedestal" level="ALL" />
  <logger name="hammock-cafe" level="ALL" />
  <logger name="user" level="ALL" />


</configuration>

